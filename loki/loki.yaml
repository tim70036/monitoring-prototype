auth_enabled: false

server:
  http_listen_port: 3100

common:
  path_prefix: /loki
  replication_factor: 1
  ring:
    instance_addr: 127.0.0.1
    kvstore:
      store: inmemory

# The storage_config block configures one of many possible stores for both the index and chunks.
# Which configuration to be picked should be defined in schema_config block.
storage_config:
  filesystem:
    directory: /loki/chunks
  boltdb_shipper:
    active_index_directory: /loki/index
    cache_location: /loki/index-cache
  tsdb_shipper:
    active_index_directory: /loki/tsdb-index
    cache_location: /loki/tsdb-index-cache

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h
      chunks:
        prefix: chunk_
        period: 24h
    - from: 2024-08-22
      store: tsdb
      object_store: filesystem
      schema: v13
      index:
        prefix: index_
        period: 24h

# Configures limits per-tenant or globally.
limits_config:
  # Retention to apply for the store, if the retention is enable on the compactor side.
  retention_period: 336h

# The compactor block configures the compactor component. This component periodically compacts index shards to more performant forms.
compactor:
  compaction_interval: 10m
  retention_delete_delay: 2h # The delay after which the compactor will delete marked chunks.
  retention_enabled: true # Set retention_enabled to true. Without this, the Compactor will only compact tables. The index period must be 24h.
  delete_request_cancel_period: 24h
  delete_request_store: filesystem

ingester:
  # chunk_encoding The chunk encoding determines which compression
  # algorithm is used for our chunks in storage. gzip is the default
  # and has the best compression ratio, but we suggest snappy for
  # its faster decompression rate, which results in better query
  # speeds.
  chunk_encoding: snappy

  # The ingester WAL (Write Ahead Log) records incoming logs and stores them on
  # the local file systems in order to guarantee persistence of acknowledged data
  # in the event of a process crash.
  wal:
    # WAL could use a lot of disk space. Can enable it if we have enough $$$$$$.
    # Based on tests in real world:
    # Numbers from an ingester with 5000 series ingesting ~5mb/s.
    # Checkpoint period was 5mins.
    # disk utilization on a WAL-only disk was steady at ~10-15GB.
    enabled: false